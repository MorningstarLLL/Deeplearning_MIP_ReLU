{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr 23 16:02:33 2020\n",
    "\n",
    "@author: JF LIU\n",
    "\"\"\"\n",
    "#%% data import\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import random \n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#from torchtext import data \n",
    "#from torchtext import datasets\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/JF LIU/Desktop/DLproject/para\")\n",
    "# BATCH_SIZE = 64\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "# train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "#     (train_data, valid_data, test_data), \n",
    "#     batch_size = BATCH_SIZE, \n",
    "#     device = device)\n",
    "\n",
    "#model\n",
    "\n",
    "class nlp_cnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "\n",
    "        # print(embedded.shape)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n",
    "\n",
    "\n",
    "INPUT_DIM =  20574 #len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 25\n",
    "N_FILTERS = 25\n",
    "FILTER_SIZES = [3,4]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = 0#TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# model = nlp_cnn(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "\n",
    "# print(model)\n",
    "# pretrained_embeddings = TEXT.vocab.vectors\n",
    "# model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "\n",
    "# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "# model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "model_2 = nlp_cnn(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "\n",
    "model_2.load_state_dict(torch.load('Model_1_State_Dict'))\n",
    "\n",
    "params = []\n",
    "for name, param in model_2.named_parameters():\n",
    "  if param.requires_grad:\n",
    "    params.append((name, param.data.numpy()))\n",
    "#print(params)\n",
    "\n",
    "X = torch.load(\"Model_1_Intermediates_batch_0_input_embed\")\n",
    "X.shape\n",
    "X = np.array(X)\n",
    "\n",
    "cnn_output = torch.load(\"Model_1_Intermediates_batch_0_fc\")\n",
    "cnn_output = np.array(cnn_output)\n",
    "\n",
    "weight1 = params[1][1].squeeze(1)\n",
    "bias1 = params[2][1]\n",
    "weight2 = params[3][1].squeeze(1)\n",
    "bias2 = params[4][1]\n",
    "weight_fc = params[5][1]\n",
    "bias_fc = params[6][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MIP \n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#X = X0\n",
    "#W = weight1[0]\n",
    "#b = bias1[0]\n",
    "#cnn_output = cnn_output[0]\n",
    "\n",
    "def minimize_l2(X, W1, b1, W2, b2, weight_fc, bias_fc, cnn_output, K=3, kernel_size=(3,25)):\n",
    "    global m\n",
    "    weight1=W1 \n",
    "    bias1=b1\n",
    "    weight2=W2\n",
    "    bias2=b2\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : TYPE 2-dimension( height, channels=100)\n",
    "        node values in cnn \n",
    "    W : TYPE 3-dimension(out_channels, kernel[0], kernel[1])\n",
    "        weights in cnn\n",
    "    b : TYPE 1-dimension(channels, )\n",
    "        bias in cnn\n",
    "    K : # of layers\n",
    "    kernel_size : a tuple (3,100) for example, the same as the size in CNN \n",
    "    objective function: minimize manhattan distance between original input X\n",
    "                        and new input Y                   \n",
    "    variables: new input Y\n",
    "    \"\"\"\n",
    "    # code for one batch one channel\n",
    "    #m = gp.Model()\n",
    "    #y = m.addVars(64,X.shape[1],100, name=\"y\")\n",
    "    y = m.addVars(X.shape[0], X.shape[1], lb=-GRB.INFINITY, name=\"y\")\n",
    "    output = m.addVar(lb=-GRB.INFINITY, name=\"output\")\n",
    "    tmp = m.addVar(lb=-GRB.INFINITY, name=\"tmp\")\n",
    "    m.update()\n",
    "    lb = X*(1-0.05)\n",
    "    ub = X*(1+0.05)\n",
    "    d = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            v1 = lb[i,j]\n",
    "            v2 = ub[i,j]\n",
    "            m.addConstr( y[i,j] >= v1 )\n",
    "            m.addConstr( y[i,j] <= v2 )\n",
    "            d = d + (y[i,j] - X[i,j]) * (y[i,j] - X[i,j])\n",
    "    dist = m.addVar()\n",
    "    m.update()\n",
    "    m.setObjective( dist , GRB.MINIMIZE)\n",
    "    m.addConstr(dist == d)\n",
    "    m.update()\n",
    "    m.setParam(\"NonConvex\", 2)    \n",
    "    #m.setObjective( L2(y, X) , GRB.MINIMIZE)\n",
    "    #m.addGenConstrMax(z[0,2], [y[0,2,1], 0.0], name=\"maxconstr\")\n",
    "    def conv2vec(y, X, weight, bias, w_fc, b_fc, kernel_size):\n",
    "        \"\"\"\n",
    "        x is the input with size (batch, height, channels=100)\n",
    "        y : the gurobi variables\n",
    "        weight_c, bias_c : weight, bias for each channel\n",
    "        \"\"\"\n",
    "        global m\n",
    "        nonlocal tmp, output\n",
    "        z = m.addVars(X.shape[0], lb=-GRB.INFINITY, vtype=GRB.BINARY, name=\"z\")\n",
    "        a = m.addVars(X.shape[0], lb=0.0, name=\"a\")\n",
    "        c = m.addVars(X.shape[0], lb=0.0, name=\"c\")\n",
    "        #batch_size = X.shape[0]\n",
    "        #kernel_size = (3,50)\n",
    "        length = X.shape[0] - kernel_size[0] + 1 \n",
    "        k_size = kernel_size[0]\n",
    "        bias_c = bias\n",
    "        #bias_c = 0.23\n",
    "        weight_c = weight\n",
    "        #vec = np.zeros((batch_size, length, 1))\n",
    "        #dist = {}\n",
    "        for j in range(length):\n",
    "            # elementwise multipilication for convolutional layer\n",
    "            tp1=bias_c\n",
    "            for k in range(k_size):\n",
    "                for n in range(kernel_size[1]):\n",
    "                    tp1 = tp1 + weight_c[k,n] * y[j+k,n]  \n",
    "                    #print(tp1)\n",
    "                    #m.addGenConstrMax(z[i,j], [tp1, 0.0])\n",
    "                    #print(tp1)\n",
    "                    #a[0,1243]\n",
    "            m.addConstr(a[j]-c[j] ==  tp1 )\n",
    "            m.addGenConstrIndicator(z[j], True, a[j] <= 0.0)\n",
    "            m.addGenConstrIndicator(z[j], False, c[j] <= 0.0)           \n",
    "        m.update()\n",
    "        u=m.addVar(name=\"u\")\n",
    "        tmp = tmp + w_fc * u \n",
    "        m.addGenConstrMax(u, [a[i] for i in range(X.shape[0])])\n",
    "        m.update()    \n",
    "        #m.feasRelax()\n",
    "    for i in range(weight1.shape[0]):\n",
    "        conv2vec(y, X, weight1[i], bias1[i], weight_fc[0,i], bias_fc, kernel_size)\n",
    "    for i in range(weight2.shape[0]):\n",
    "        conv2vec(y, X, weight2[i], bias2[i], weight_fc[0,25+i], bias_fc, kernel_size = (4,25))\n",
    "    tmp = tmp + bias_fc\n",
    "    print(tmp)\n",
    "    m.addConstr(output == tmp)\n",
    "    m.addConstr( tmp * cnn_output <= 0.0 )\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    if m.status == GRB.INFEASIBLE:\n",
    "        m.feasRelaxS(1, False, False, True)\n",
    "        m.optimize()\n",
    "    vals = m.getVars() \n",
    "    return (vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "def extract_y(new_example, X):\n",
    "    dim1 = X.shape[0]\n",
    "    dim2 = X.shape[1]\n",
    "    yvalue = [0] * (dim1*dim2)\n",
    "    for i in range(dim1*dim2):\n",
    "        yvalue[i] = new_example[i].X\n",
    "    yvalue = np.reshape(yvalue, (dim1*dim2))\n",
    "    return (yvalue)    \n",
    "new_y = np.zeros((64,25,25))   \n",
    "new_output = np.zeros((64,1))  \n",
    "for i in range(64):\n",
    "    example = X[i,:,:]\n",
    "    m = gp.Model()\n",
    "    new_example = minimize_l2(example, weight1, bias1, weight2, bias2, weight_fc, \\\n",
    "                          bias_fc[0], cnn_output[i][0],\\\n",
    "                          K=3, kernel_size=(3,25))\n",
    "    new_y[i,:,:] = extract_y(new_example, example).reshape((25,25))\n",
    "    new_output[i,:] = new_example[626].X\n",
    "\n",
    "toc = time.time() - tic\n",
    "print(\"*************time**************\")\n",
    "print(toc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
